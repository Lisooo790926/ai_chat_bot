# 如何在不動大模型參數的情況下，強化它的能力？（上）

## Overview
This video discusses methods to enhance the capabilities of large language models (LLMs) without retraining or modifying their parameters. It focuses on techniques to improve LLM performance by breaking down complex tasks into simpler sub-tasks, enabling self-reflection for error correction, and leveraging external tools like search engines and code interpreters. The video uses examples with ChatGPT and GPT-4 to illustrate these concepts.

## Detailed Summary
The video explores several strategies to improve LLM performance without altering the underlying model. One key method involves decomposing complex tasks into smaller, more manageable steps. For instance, instead of asking an LLM to generate an entire report on generative AI, the task can be broken down into creating an outline, writing individual sections based on the outline, and summarizing previous sections to maintain coherence. This approach aligns with the concept of "Recursive Reprompting and Revision," where LLMs can write longer narratives by first structuring an outline and then filling in the details for each section.

The video also discusses the concept of "Chain of Thought," which involves prompting the LLM to think step-by-step. This process forces the model to detail its reasoning, effectively breaking down the problem-solving process into smaller, more manageable steps. The speaker clarifies that Chain of Thought is less effective on models like GPT-3.5 because they often perform this step already.

Another technique presented is enabling self-reflection, where the LLM is prompted to check its own outputs for errors. While seemingly counterintuitive, this method can be effective because verifying a solution is often easier than generating it. The video uses the example of a chicken-and-rabbit problem to illustrate how even a flawed LLM can recognize incorrect answers. This self-reflection ability is further explored through the "Constitutional AI" approach, where the model critiques its own responses based on ethical and moral principles, leading to more responsible outputs.

Finally, the video highlights the benefits of equipping LLMs with external tools. Search engines enable models to access up-to-date information, while code interpreters allow them to perform complex calculations and manipulations. The speaker uses the example of GPT-4 using a code interpreter to solve a system of equations, and how it can use a text-to-image AI to generate images based on textual descriptions. The video concludes by describing how these tools are used with text-generation, using search or code as an intermediate step.

## Key Points
- Complex tasks can be broken down into smaller, simpler tasks to improve LLM performance.
- Chain of Thought prompting encourages LLMs to detail their reasoning, which helps in problem-solving.
- LLMs can be prompted to self-reflect and correct their own errors, improving accuracy.
- External tools like search engines and code interpreters can enhance LLM capabilities.
- LLMs use text-generation to decide when and how to use external tools.

## Conclusion
The video emphasizes that significant improvements in LLM performance can be achieved without retraining or modifying the model's parameters. By strategically breaking down tasks, enabling self-reflection, and integrating external tools, the capabilities of LLMs can be greatly enhanced, leading to more accurate, responsible, and versatile outputs. The speaker underscores that these techniques work by manipulating the input and output processes of the LLM while leaving the core model untouched.
